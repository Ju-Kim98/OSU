{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part4: Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RMSLE on the development set:', 0.1520164459135018)\n"
     ]
    }
   ],
   "source": [
    "#Part2. Naive data processing: binarizing all fields\n",
    "\n",
    "train_data = pd.read_csv('my_train.csv').astype(str)\n",
    "dev_data = pd.read_csv('my_dev.csv').astype(str)\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train = encoder.fit_transform(train_data.drop(['Id', 'SalePrice'], axis=1))\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "\n",
    "X_dev = encoder.transform(dev_data.drop(['Id', 'SalePrice'], axis=1))\n",
    "y_dev = np.log(dev_data['SalePrice'].astype(float))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_dev)\n",
    "rmsle = np.sqrt(mean_squared_log_error(np.exp(y_dev), np.exp(predictions)))\n",
    "print(\"RMSLE on the development set:\", rmsle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('New dev error:', 0.1424433144859072)\n"
     ]
    }
   ],
   "source": [
    "#Part3.  Smarter binarization: Only binarizing categorical features\n",
    "\n",
    "train_data = pd.read_csv('my_train.csv').astype(str)\n",
    "dev_data = pd.read_csv('my_dev.csv').astype(str)\n",
    "\n",
    "categorical_cols = train_data.select_dtypes(include=['object']).columns\n",
    "numerical_cols = train_data.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Handle missing values (you can choose a suitable imputation strategy)\n",
    "train_data[numerical_cols] = train_data[numerical_cols].fillna(train_data[numerical_cols].mean())\n",
    "train_data[categorical_cols] = train_data[categorical_cols].fillna('missing')\n",
    "\n",
    "dev_data[numerical_cols] = dev_data[numerical_cols].fillna(train_data[numerical_cols].mean())\n",
    "dev_data[categorical_cols] = dev_data[categorical_cols].fillna('missing')\n",
    "\n",
    "# One-hot encode only the categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_cat = encoder.fit_transform(train_data[categorical_cols])\n",
    "X_dev_cat = encoder.transform(dev_data[categorical_cols])\n",
    "\n",
    "# Combine one-hot encoded categorical features with the original numerical features\n",
    "X_train = np.hstack((X_train_cat.toarray(), train_data[numerical_cols].values))\n",
    "X_dev = np.hstack((X_dev_cat.toarray(), dev_data[numerical_cols].values))\n",
    "\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "y_dev = np.log(dev_data['SalePrice'].astype(float))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_dev)\n",
    "rmsle = np.sqrt(mean_squared_log_error(np.exp(y_dev), np.exp(predictions)))\n",
    "print(\"New dev error:\", rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best alpha:', 6.135907273413176)\n",
      "('4-1 RMSLE on the development set:', 0.14031919940125231)\n"
     ]
    }
   ],
   "source": [
    "#Part4-1:linear regression\n",
    "alphas = np.logspace(-2, 2, 100)  \n",
    "\n",
    "best_alpha = None\n",
    "best_rmsle = float('inf')\n",
    "\n",
    "# Tuning alpha\n",
    "for alpha in alphas:\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_dev)\n",
    "    rmsle = np.sqrt(mean_squared_log_error(np.exp(y_dev), np.exp(predictions)))\n",
    "    \n",
    "    if rmsle < best_rmsle:\n",
    "        best_rmsle = rmsle\n",
    "        best_alpha = alpha\n",
    "\n",
    "# Retrain with best alpha\n",
    "model = Ridge(alpha=best_alpha)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_dev)\n",
    "num1_rmsle = np.sqrt(mean_squared_log_error(np.exp(y_dev), np.exp(predictions)))\n",
    "\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"4-1 RMSLE on the development set:\", num1_rmsle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('non-linear regression with PolynomialFeatures: ', 0.2993164748931549)\n"
     ]
    }
   ],
   "source": [
    "#Part4-2: non-linear regression with PolynomialFeatures\n",
    "\n",
    "train_data = pd.read_csv('my_train.csv')\n",
    "dev_data = pd.read_csv('my_dev.csv')\n",
    "\n",
    "categorical_cols = train_data.select_dtypes(include=['object']).columns\n",
    "numerical_cols = train_data.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Handle missing values\n",
    "train_data[numerical_cols] = train_data[numerical_cols].fillna(train_data[numerical_cols].mean())\n",
    "train_data[categorical_cols] = train_data[categorical_cols].fillna('missing')\n",
    "\n",
    "dev_data[numerical_cols] = dev_data[numerical_cols].fillna(train_data[numerical_cols].mean())\n",
    "dev_data[categorical_cols] = dev_data[categorical_cols].fillna('missing')\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_cat = encoder.fit_transform(train_data[categorical_cols])\n",
    "X_dev_cat = encoder.transform(dev_data[categorical_cols])\n",
    "\n",
    "# Generate polynomial features for numerical features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(train_data[numerical_cols])\n",
    "X_dev_poly = poly.transform(dev_data[numerical_cols])\n",
    "\n",
    "# Combine one-hot encoded categorical features with polynomial numerical features\n",
    "X_train = np.hstack((X_train_cat.toarray(), X_train_poly))\n",
    "X_dev = np.hstack((X_dev_cat.toarray(), X_dev_poly))\n",
    "\n",
    "# target variable\n",
    "y_train = np.log(train_data['SalePrice'].astype(float))\n",
    "y_dev = np.log(dev_data['SalePrice'].astype(float))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_dev)\n",
    "rmsle_2 = np.sqrt(mean_squared_log_error(np.exp(y_dev), np.exp(predictions)))\n",
    "\n",
    "print(\"non-linear regression with PolynomialFeatures: \",rmsle_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1727581847643204,         Id      SalePrice\n",
       " 0     1461  128633.029473\n",
       " 1     1462    8689.928732\n",
       " 2     1463  195572.120419\n",
       " 3     1464  212989.881972\n",
       " 4     1465  195708.112526\n",
       " 5     1466  182178.596630\n",
       " 6     1467  168941.957295\n",
       " 7     1468  166005.509156\n",
       " 8     1469  196550.373525\n",
       " 9     1470  125819.185801\n",
       " 10    1471  202819.768557\n",
       " 11    1472  103506.123919\n",
       " 12    1473  156805.532156\n",
       " 13    1474  145160.981194\n",
       " 14    1475  120800.089309\n",
       " 15    1476  397496.684628\n",
       " 16    1477  262854.279940\n",
       " 17    1478  332177.319005\n",
       " 18    1479  316146.348014\n",
       " 19    1480  330147.376839\n",
       " 20    1481  318048.758481\n",
       " 21    1482  221713.507288\n",
       " 22    1483  180630.277712\n",
       " 23    1484  168980.036541\n",
       " 24    1485  193194.645806\n",
       " 25    1486  198370.406773\n",
       " 26    1487  396530.117477\n",
       " 27    1488  250368.206033\n",
       " 28    1489  216055.607666\n",
       " 29    1490  236953.128322\n",
       " ...    ...            ...\n",
       " 1429  2890   82815.631399\n",
       " 1430  2891  145618.637742\n",
       " 1431  2892   41991.918301\n",
       " 1432  2893   73171.457388\n",
       " 1433  2894   43863.836117\n",
       " 1434  2895  368853.846814\n",
       " 1435  2896  280911.067657\n",
       " 1436  2897  214943.135429\n",
       " 1437  2898  167064.728263\n",
       " 1438  2899  214628.408832\n",
       " 1439  2900  169560.735314\n",
       " 1440  2901  241389.221209\n",
       " 1441  2902  195656.013616\n",
       " 1442  2903  324956.882534\n",
       " 1443  2904  350112.948163\n",
       " 1444  2905   90842.432054\n",
       " 1445  2906  217501.371380\n",
       " 1446  2907  112248.380604\n",
       " 1447  2908  130573.872724\n",
       " 1448  2909  120338.964786\n",
       " 1449  2910   79798.242908\n",
       " 1450  2911   72958.558950\n",
       " 1451  2912  146225.299752\n",
       " 1452  2913   78516.077471\n",
       " 1453  2914   76136.136130\n",
       " 1454  2915   88466.672645\n",
       " 1455  2916   74627.176633\n",
       " 1456  2917  161244.649120\n",
       " 1457  2918  115220.291271\n",
       " 1458  2919  233906.043453\n",
       " \n",
       " [1459 rows x 2 columns])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4-4: Ridge regression model with a preprocessing pipeline\n",
    "train_data = pd.read_csv('my_train.csv')\n",
    "dev_data = pd.read_csv('my_dev.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_data.drop(['Id', 'SalePrice'], axis=1)\n",
    "y_train = np.log(train_data['SalePrice'])  # Log transform the target for normality\n",
    "X_dev = dev_data.drop(['Id', 'SalePrice'], axis=1)\n",
    "y_dev = np.log(dev_data['SalePrice'])\n",
    "X_test = test_data.drop(['Id'], axis=1)\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Pipeline for numerical features\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean\n",
    "    ('scaler', StandardScaler()),  # Scale features\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False))  # Add polynomial features\n",
    "])\n",
    "\n",
    "# Pipeline for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Handle missing values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One hot encode categorical variables\n",
    "])\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_cols),\n",
    "        ('cat', categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Create a Ridge regression model with preprocessor\n",
    "ridge_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('regressor', Ridge(alpha=1.0))])\n",
    "\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "\n",
    "dev_predictions = ridge_pipeline.predict(X_dev)\n",
    "dev_rmsle = np.sqrt(mean_squared_log_error(np.exp(y_dev), np.exp(dev_predictions)))\n",
    "\n",
    "test_predictions = np.exp(ridge_pipeline.predict(X_test))  # Inverse of log transform\n",
    "\n",
    "submission_final = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': test_predictions})\n",
    "\n",
    "submission_final.to_csv('submission_final.csv', index=False)\n",
    "\n",
    "dev_rmsle, submission_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
